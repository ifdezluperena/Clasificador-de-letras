{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from exif import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos si nuestras imagenes tienen metadatos para obtener de una amnera facil las etiquetas.\n",
    "\n",
    "img_path = '../data/train/Letter_A_may_2.png'\n",
    "\n",
    "with open(img_path, 'rb') as img_file:\n",
    "    image = Image(img_file)\n",
    "\n",
    "print(image.has_exif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos las imagenes de nuestro dataset no tienen metadatos, por lo tanto tendremos que buscar las etiquetas para nuestras neuronas de salida de otra manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queremos que nuestras imagenes tengan unas dimensiones no muy grandes.\n",
    "width = 32\n",
    "height = 32\n",
    "\n",
    "\n",
    "train_path = '../data/train'\n",
    "test_path = '../data/test'\n",
    "\n",
    "train_x = x_generator(train_path, width, height)\n",
    "train_labels = labels_generator(train_path)\n",
    "train_y = y_generator(train_path, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos nuestros datos de train a arrays.\n",
    "\n",
    "x_data_train = np.array(train_x)\n",
    "y_data_train = np.array(train_y, dtype=np.dtype(np.float32))\n",
    "\n",
    "print(x_data_train.shape[0])\n",
    "print(y_data_train.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('La cantidad de neuronas de salida es de:',len(train_labels))\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data_train = np.array(train_x).reshape(x_data_train.shape[0], width, height, 3)\n",
    "\n",
    "num_classes = len(train_labels)\n",
    "\n",
    "#y_data_train = to_categorical(y_data_train) Ya la tenemos categorizada.\n",
    "print(y_data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos obtenido nuestras etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "rango_rotacion = 30\n",
    "mov_ancho = 0.25\n",
    "mov_alto = 0.25\n",
    "rango_acercamiento=[0.5,1.5]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = rango_rotacion,\n",
    "    width_shift_range = mov_ancho,\n",
    "    height_shift_range = mov_alto,\n",
    "    zoom_range=rango_acercamiento,\n",
    "\n",
    ")\n",
    "\n",
    "datagen.fit(x_data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los datos para entrenar saldran del datagen, de manera que sean generados con las transformaciones que indicamos\n",
    "data_gen_entrenamiento = datagen.flow(x_data_train, y_data_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos los datos.\n",
    "\n",
    "x_data_train_normalized = x_data_train.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(width,height,3)),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(100, activation='relu'),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(x_data_train_normalized, y_data_train, epochs= 80, batch_size = 32, steps_per_epoch=int(np.ceil(60000 / float(32))))\n",
    "\n",
    "model.save('model_80_sigmoid_softmax_relu_32.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicciones\n",
    "model_test = models.load_model('model_60_sigmoid.keras')\n",
    "\n",
    "img = cv2.imread('../data/test/Letter_b_min_186.png')\n",
    "img_resized = cv2.resize(img,(28,28))\n",
    "result = model_test.predict(np.array([img_resized]))\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
