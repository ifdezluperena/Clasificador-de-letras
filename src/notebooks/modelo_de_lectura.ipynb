{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "project_root = os.path.abspath(\"..\")   # sube desde /notebooks a /\n",
    "\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from utils.functions import*\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras import layers, models\n",
    "from keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "from exif import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "#Comprobamos si nuestras imagenes tienen metadatos para obtener de una amnera facil las etiquetas.\n",
    "\n",
    "img_path = '../data/train/Letter_A_may_2.png'\n",
    "\n",
    "with open(img_path, 'rb') as img_file:\n",
    "    image = Image(img_file)\n",
    "\n",
    "print(image.has_exif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como vemos las imagenes de nuestro dataset no tienen metadatos, por lo tanto tendremos que buscar las etiquetas para nuestras neuronas de salida de otra manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Queremos que nuestras imagenes tengan unas dimensiones no muy grandes.\n",
    "width = 32\n",
    "height = 32\n",
    "\n",
    "\n",
    "train_path = '../data/train'\n",
    "test_path = '../data/test'\n",
    "\n",
    "train_x = x_generator(train_path, width, height)\n",
    "train_labels = labels_generator(train_path)\n",
    "train_y = y_generator(train_path, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35325\n",
      "(35325, 52)\n"
     ]
    }
   ],
   "source": [
    "#Pasamos nuestros datos de train a arrays.\n",
    "\n",
    "x_data_train = np.array(train_x)\n",
    "y_data_train = np.array(train_y, dtype=np.dtype(np.float32))\n",
    "\n",
    "print(x_data_train.shape[0])\n",
    "print(y_data_train.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La cantidad de neuronas de salida es de: 52\n",
      "['A', 'a', 'B', 'b', 'C', 'c', 'D', 'd', 'E', 'e', 'F', 'f', 'G', 'g', 'H', 'h', 'I', 'i', 'J', 'j', 'K', 'k', 'L', 'l', 'M', 'm', 'N', 'n', 'O', 'o', 'P', 'p', 'Q', 'q', 'R', 'r', 'S', 's', 'T', 't', 'U', 'u', 'V', 'v', 'W', 'w', 'X', 'x', 'Y', 'y', 'Z', 'z']\n"
     ]
    }
   ],
   "source": [
    "print('La cantidad de neuronas de salida es de:',len(train_labels))\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35325, 52)\n"
     ]
    }
   ],
   "source": [
    "x_data_train = np.array(train_x).reshape(x_data_train.shape[0], width, height, 3)\n",
    "\n",
    "num_classes = len(train_labels)\n",
    "\n",
    "#y_data_train = to_categorical(y_data_train) Ya la tenemos categorizada.\n",
    "print(y_data_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya hemos obtenido nuestras etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y_indices = np.argmax(y_data_train, axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(x_data_train, y_data_train, test_size=0.1, random_state=42, stratify=y_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "rango_rotacion = 10\n",
    "mov_ancho = 0.05\n",
    "mov_alto = 0.05\n",
    "rango_acercamiento=[0.9,1.1]\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range = rango_rotacion,\n",
    "    width_shift_range = mov_ancho,\n",
    "    height_shift_range = mov_alto,\n",
    "    zoom_range=rango_acercamiento,\n",
    "    rescale=1./225\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Los datos para entrenar saldran del datagen, de manera que sean generados con las transformaciones que indicamos\n",
    "data_gen_entrenamiento = datagen.flow(X_train, y_train, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "generador_validacion = val_datagen.flow(X_val, y_val, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizamos los datos.\n",
    "\n",
    "x_data_train_normalized = x_data_train.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    layers.Input(shape=(width,height,3)),\n",
    "\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D(2,2),\n",
    "\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(num_classes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',   # qué métrica vigilar\n",
    "    factor=0.5,           # reduce a la mitad la LR\n",
    "    patience=5,           # espera 5 epochs sin mejora\n",
    "    min_lr=1e-6,          # límite inferior de LR\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 34ms/step - accuracy: 0.8111 - loss: 0.6031 - val_accuracy: 0.8664 - val_loss: 0.4345 - learning_rate: 0.0010\n",
      "Epoch 2/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8135 - loss: 0.5832 - val_accuracy: 0.8695 - val_loss: 0.4087 - learning_rate: 0.0010\n",
      "Epoch 3/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8096 - loss: 0.5942 - val_accuracy: 0.8658 - val_loss: 0.4241 - learning_rate: 0.0010\n",
      "Epoch 4/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8171 - loss: 0.5891 - val_accuracy: 0.8582 - val_loss: 0.4428 - learning_rate: 0.0010\n",
      "Epoch 5/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8109 - loss: 0.6014 - val_accuracy: 0.8639 - val_loss: 0.4401 - learning_rate: 0.0010\n",
      "Epoch 6/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.8141 - loss: 0.5927 - val_accuracy: 0.8511 - val_loss: 0.4805 - learning_rate: 0.0010\n",
      "Epoch 7/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8121 - loss: 0.5890\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8137 - loss: 0.5883 - val_accuracy: 0.8457 - val_loss: 0.4901 - learning_rate: 0.0010\n",
      "Epoch 8/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 35ms/step - accuracy: 0.8308 - loss: 0.5235 - val_accuracy: 0.8755 - val_loss: 0.4002 - learning_rate: 5.0000e-04\n",
      "Epoch 9/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8335 - loss: 0.5103 - val_accuracy: 0.8622 - val_loss: 0.4212 - learning_rate: 5.0000e-04\n",
      "Epoch 10/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8343 - loss: 0.5113 - val_accuracy: 0.8497 - val_loss: 0.4781 - learning_rate: 5.0000e-04\n",
      "Epoch 11/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8359 - loss: 0.5085 - val_accuracy: 0.8664 - val_loss: 0.4130 - learning_rate: 5.0000e-04\n",
      "Epoch 12/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.8385 - loss: 0.5019 - val_accuracy: 0.8783 - val_loss: 0.3866 - learning_rate: 5.0000e-04\n",
      "Epoch 13/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8383 - loss: 0.4966 - val_accuracy: 0.8726 - val_loss: 0.3981 - learning_rate: 5.0000e-04\n",
      "Epoch 14/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8369 - loss: 0.5121 - val_accuracy: 0.8630 - val_loss: 0.4166 - learning_rate: 5.0000e-04\n",
      "Epoch 15/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8380 - loss: 0.5012 - val_accuracy: 0.8797 - val_loss: 0.3762 - learning_rate: 5.0000e-04\n",
      "Epoch 16/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8383 - loss: 0.4922 - val_accuracy: 0.8605 - val_loss: 0.4442 - learning_rate: 5.0000e-04\n",
      "Epoch 17/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8379 - loss: 0.5017 - val_accuracy: 0.8774 - val_loss: 0.3893 - learning_rate: 5.0000e-04\n",
      "Epoch 18/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.8374 - loss: 0.5003 - val_accuracy: 0.8723 - val_loss: 0.3918 - learning_rate: 5.0000e-04\n",
      "Epoch 19/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.8389 - loss: 0.4957 - val_accuracy: 0.8661 - val_loss: 0.4406 - learning_rate: 5.0000e-04\n",
      "Epoch 20/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.8396 - loss: 0.4976 - val_accuracy: 0.8828 - val_loss: 0.3641 - learning_rate: 5.0000e-04\n",
      "Epoch 21/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8391 - loss: 0.5013 - val_accuracy: 0.8664 - val_loss: 0.4115 - learning_rate: 5.0000e-04\n",
      "Epoch 22/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8412 - loss: 0.4911 - val_accuracy: 0.8726 - val_loss: 0.4060 - learning_rate: 5.0000e-04\n",
      "Epoch 23/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8397 - loss: 0.4863 - val_accuracy: 0.8738 - val_loss: 0.4007 - learning_rate: 5.0000e-04\n",
      "Epoch 24/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8432 - loss: 0.4827 - val_accuracy: 0.8780 - val_loss: 0.3855 - learning_rate: 5.0000e-04\n",
      "Epoch 25/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8405 - loss: 0.4972\n",
      "Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8421 - loss: 0.4932 - val_accuracy: 0.8780 - val_loss: 0.3778 - learning_rate: 5.0000e-04\n",
      "Epoch 26/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 28ms/step - accuracy: 0.8477 - loss: 0.4632 - val_accuracy: 0.8794 - val_loss: 0.3735 - learning_rate: 2.5000e-04\n",
      "Epoch 27/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8505 - loss: 0.4505 - val_accuracy: 0.8806 - val_loss: 0.3699 - learning_rate: 2.5000e-04\n",
      "Epoch 28/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.8519 - loss: 0.4541 - val_accuracy: 0.8743 - val_loss: 0.3839 - learning_rate: 2.5000e-04\n",
      "Epoch 29/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8555 - loss: 0.4483 - val_accuracy: 0.8755 - val_loss: 0.3912 - learning_rate: 2.5000e-04\n",
      "Epoch 30/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8537 - loss: 0.4463\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8535 - loss: 0.4439 - val_accuracy: 0.8814 - val_loss: 0.3784 - learning_rate: 2.5000e-04\n",
      "Epoch 31/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8560 - loss: 0.4388 - val_accuracy: 0.8840 - val_loss: 0.3650 - learning_rate: 1.2500e-04\n",
      "Epoch 32/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 32ms/step - accuracy: 0.8581 - loss: 0.4357 - val_accuracy: 0.8760 - val_loss: 0.3786 - learning_rate: 1.2500e-04\n",
      "Epoch 33/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8584 - loss: 0.4387 - val_accuracy: 0.8740 - val_loss: 0.3831 - learning_rate: 1.2500e-04\n",
      "Epoch 34/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 33ms/step - accuracy: 0.8599 - loss: 0.4279 - val_accuracy: 0.8732 - val_loss: 0.3892 - learning_rate: 1.2500e-04\n",
      "Epoch 35/80\n",
      "\u001b[1m993/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8601 - loss: 0.4162\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8593 - loss: 0.4213 - val_accuracy: 0.8786 - val_loss: 0.3665 - learning_rate: 1.2500e-04\n",
      "Epoch 36/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8611 - loss: 0.4250 - val_accuracy: 0.8808 - val_loss: 0.3723 - learning_rate: 6.2500e-05\n",
      "Epoch 37/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8631 - loss: 0.4222 - val_accuracy: 0.8797 - val_loss: 0.3712 - learning_rate: 6.2500e-05\n",
      "Epoch 38/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8638 - loss: 0.4208 - val_accuracy: 0.8823 - val_loss: 0.3620 - learning_rate: 6.2500e-05\n",
      "Epoch 39/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8625 - loss: 0.4216 - val_accuracy: 0.8820 - val_loss: 0.3785 - learning_rate: 6.2500e-05\n",
      "Epoch 40/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8613 - loss: 0.4178 - val_accuracy: 0.8834 - val_loss: 0.3591 - learning_rate: 6.2500e-05\n",
      "Epoch 41/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8634 - loss: 0.4185 - val_accuracy: 0.8831 - val_loss: 0.3635 - learning_rate: 6.2500e-05\n",
      "Epoch 42/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8636 - loss: 0.4167 - val_accuracy: 0.8808 - val_loss: 0.3711 - learning_rate: 6.2500e-05\n",
      "Epoch 43/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8670 - loss: 0.4034 - val_accuracy: 0.8828 - val_loss: 0.3681 - learning_rate: 6.2500e-05\n",
      "Epoch 44/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8653 - loss: 0.4130 - val_accuracy: 0.8777 - val_loss: 0.3735 - learning_rate: 6.2500e-05\n",
      "Epoch 45/80\n",
      "\u001b[1m993/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8658 - loss: 0.4020\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8630 - loss: 0.4088 - val_accuracy: 0.8777 - val_loss: 0.3780 - learning_rate: 6.2500e-05\n",
      "Epoch 46/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8650 - loss: 0.4113 - val_accuracy: 0.8817 - val_loss: 0.3719 - learning_rate: 3.1250e-05\n",
      "Epoch 47/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8662 - loss: 0.4057 - val_accuracy: 0.8823 - val_loss: 0.3673 - learning_rate: 3.1250e-05\n",
      "Epoch 48/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 31ms/step - accuracy: 0.8664 - loss: 0.4060 - val_accuracy: 0.8831 - val_loss: 0.3711 - learning_rate: 3.1250e-05\n",
      "Epoch 49/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.8649 - loss: 0.4077 - val_accuracy: 0.8837 - val_loss: 0.3697 - learning_rate: 3.1250e-05\n",
      "Epoch 50/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8643 - loss: 0.4141\n",
      "Epoch 50: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.8641 - loss: 0.4124 - val_accuracy: 0.8823 - val_loss: 0.3652 - learning_rate: 3.1250e-05\n",
      "Epoch 51/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.8652 - loss: 0.4121 - val_accuracy: 0.8825 - val_loss: 0.3667 - learning_rate: 1.5625e-05\n",
      "Epoch 52/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8644 - loss: 0.4078 - val_accuracy: 0.8828 - val_loss: 0.3670 - learning_rate: 1.5625e-05\n",
      "Epoch 53/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 29ms/step - accuracy: 0.8626 - loss: 0.4203 - val_accuracy: 0.8791 - val_loss: 0.3743 - learning_rate: 1.5625e-05\n",
      "Epoch 54/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8648 - loss: 0.4123 - val_accuracy: 0.8811 - val_loss: 0.3765 - learning_rate: 1.5625e-05\n",
      "Epoch 55/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.8680 - loss: 0.4043\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8671 - loss: 0.4069 - val_accuracy: 0.8825 - val_loss: 0.3685 - learning_rate: 1.5625e-05\n",
      "Epoch 56/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8650 - loss: 0.4086 - val_accuracy: 0.8823 - val_loss: 0.3735 - learning_rate: 7.8125e-06\n",
      "Epoch 57/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8649 - loss: 0.4092 - val_accuracy: 0.8791 - val_loss: 0.3776 - learning_rate: 7.8125e-06\n",
      "Epoch 58/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 34ms/step - accuracy: 0.8660 - loss: 0.4034 - val_accuracy: 0.8786 - val_loss: 0.3769 - learning_rate: 7.8125e-06\n",
      "Epoch 59/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8683 - loss: 0.4003 - val_accuracy: 0.8808 - val_loss: 0.3739 - learning_rate: 7.8125e-06\n",
      "Epoch 60/80\n",
      "\u001b[1m993/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8651 - loss: 0.4077\n",
      "Epoch 60: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8683 - loss: 0.4010 - val_accuracy: 0.8814 - val_loss: 0.3717 - learning_rate: 7.8125e-06\n",
      "Epoch 61/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8681 - loss: 0.4039 - val_accuracy: 0.8808 - val_loss: 0.3705 - learning_rate: 3.9063e-06\n",
      "Epoch 62/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 33ms/step - accuracy: 0.8639 - loss: 0.4102 - val_accuracy: 0.8820 - val_loss: 0.3704 - learning_rate: 3.9063e-06\n",
      "Epoch 63/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 32ms/step - accuracy: 0.8658 - loss: 0.4118 - val_accuracy: 0.8811 - val_loss: 0.3711 - learning_rate: 3.9063e-06\n",
      "Epoch 64/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8668 - loss: 0.4065 - val_accuracy: 0.8817 - val_loss: 0.3711 - learning_rate: 3.9063e-06\n",
      "Epoch 65/80\n",
      "\u001b[1m993/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8682 - loss: 0.4014\n",
      "Epoch 65: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8676 - loss: 0.4074 - val_accuracy: 0.8820 - val_loss: 0.3717 - learning_rate: 3.9063e-06\n",
      "Epoch 66/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8679 - loss: 0.4029 - val_accuracy: 0.8825 - val_loss: 0.3719 - learning_rate: 1.9531e-06\n",
      "Epoch 67/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8657 - loss: 0.4078 - val_accuracy: 0.8820 - val_loss: 0.3731 - learning_rate: 1.9531e-06\n",
      "Epoch 68/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8676 - loss: 0.3987 - val_accuracy: 0.8823 - val_loss: 0.3723 - learning_rate: 1.9531e-06\n",
      "Epoch 69/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8686 - loss: 0.4010 - val_accuracy: 0.8811 - val_loss: 0.3724 - learning_rate: 1.9531e-06\n",
      "Epoch 70/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8688 - loss: 0.4036\n",
      "Epoch 70: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8679 - loss: 0.4016 - val_accuracy: 0.8808 - val_loss: 0.3720 - learning_rate: 1.9531e-06\n",
      "Epoch 71/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8694 - loss: 0.4046 - val_accuracy: 0.8806 - val_loss: 0.3719 - learning_rate: 1.0000e-06\n",
      "Epoch 72/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 31ms/step - accuracy: 0.8675 - loss: 0.4023 - val_accuracy: 0.8806 - val_loss: 0.3714 - learning_rate: 1.0000e-06\n",
      "Epoch 73/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 30ms/step - accuracy: 0.8676 - loss: 0.4082 - val_accuracy: 0.8814 - val_loss: 0.3704 - learning_rate: 1.0000e-06\n",
      "Epoch 74/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 30ms/step - accuracy: 0.8659 - loss: 0.4062 - val_accuracy: 0.8808 - val_loss: 0.3705 - learning_rate: 1.0000e-06\n",
      "Epoch 75/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8661 - loss: 0.4071 - val_accuracy: 0.8808 - val_loss: 0.3712 - learning_rate: 1.0000e-06\n",
      "Epoch 76/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8667 - loss: 0.4091 - val_accuracy: 0.8803 - val_loss: 0.3715 - learning_rate: 1.0000e-06\n",
      "Epoch 77/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 37ms/step - accuracy: 0.8667 - loss: 0.4066 - val_accuracy: 0.8800 - val_loss: 0.3717 - learning_rate: 1.0000e-06\n",
      "Epoch 78/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 37ms/step - accuracy: 0.8678 - loss: 0.4000 - val_accuracy: 0.8806 - val_loss: 0.3713 - learning_rate: 1.0000e-06\n",
      "Epoch 79/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 41ms/step - accuracy: 0.8659 - loss: 0.4009 - val_accuracy: 0.8806 - val_loss: 0.3718 - learning_rate: 1.0000e-06\n",
      "Epoch 80/80\n",
      "\u001b[1m994/994\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 38ms/step - accuracy: 0.8688 - loss: 0.4022 - val_accuracy: 0.8811 - val_loss: 0.3717 - learning_rate: 1.0000e-06\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(data_gen_entrenamiento, \n",
    "                    steps_per_epoch=int(np.ceil(len(X_train) / 32)),\n",
    "                    epochs=80,\n",
    "                    validation_data=generador_validacion,\n",
    "                    validation_steps=int(np.ceil(len(X_val) / 32)),\n",
    "                    callbacks=[reduce_lr])\n",
    "\n",
    "model.save('model_80_sigmoid_softmax_relu_32_128_callback.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "Vector softmax: [[1.96532217e-21 1.34480263e-12 1.40861582e-19 5.68195429e-19\n",
      "  3.21845007e-37 7.48972209e-36 9.46839212e-38 1.00000000e+00\n",
      "  0.00000000e+00 2.92264004e-22 0.00000000e+00 0.00000000e+00\n",
      "  5.74689863e-24 1.14929787e-18 1.25889845e-13 2.25410702e-26\n",
      "  6.99136245e-23 0.00000000e+00 2.46620310e-22 1.69827452e-09\n",
      "  2.29240371e-31 6.21040929e-35 1.74900227e-27 0.00000000e+00\n",
      "  8.93544311e-37 3.27254140e-36 1.21267226e-28 0.00000000e+00\n",
      "  4.52623402e-33 2.94614064e-26 2.21755528e-31 2.64361553e-33\n",
      "  1.87293973e-17 6.60863510e-17 1.81978224e-30 0.00000000e+00\n",
      "  2.07789400e-28 4.20653822e-26 0.00000000e+00 2.15010301e-20\n",
      "  1.86379253e-20 1.59281449e-10 0.00000000e+00 2.13770294e-29\n",
      "  7.48056073e-27 6.89589507e-17 5.58620032e-37 1.07391276e-29\n",
      "  0.00000000e+00 3.73074976e-21 0.00000000e+00 1.32268421e-30]]\n",
      "Clase predicha: d\n"
     ]
    }
   ],
   "source": [
    "#Predicciones\n",
    "model_test = models.load_model('model_80_sigmoid_softmax_relu_32_128_callback.keras')\n",
    "\n",
    "img = cv2.imread('../data/test/Letter_d_min_519.png')\n",
    "\n",
    "# resize + normalización\n",
    "img_resized = cv2.resize(img, (32,32))\n",
    "img_resized = img_resized.astype(\"float32\") / 255.0  \n",
    "\n",
    "# expandir a lote\n",
    "img_input = np.expand_dims(img_resized, axis=0)   # (1,32,32,3)\n",
    "\n",
    "# predicción\n",
    "result = model_test.predict(img_input)\n",
    "pred_class = train_labels[np.argmax(result, axis=1)[0]]\n",
    "\n",
    "print(\"Vector softmax:\", result)\n",
    "print(\"Clase predicha:\", pred_class)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
